{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64aeea7",
   "metadata": {},
   "source": [
    "### Tensorflow Data Pipeline\n",
    "\n",
    "<a href=\"https://www.kaggle.com/datasets/julian3833/jigsaw-unintended-bias-in-toxicity-classification?select=train.csv\"> **Jigsaw 800mb**\n",
    "    \n",
    "<a href=\"https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors\"> **Gunting, batu, kertas drgfreeman**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd9261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab655849",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw = pd.read_csv('dataset/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbc767d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192ad07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e2fc304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b8a542e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Q', 'S', 'C'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b16366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_x = ['Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Embarked']\n",
    "column_y = ['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "631c4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset_raw[column_x],\n",
    "                                                   dataset_raw[column_y],\n",
    "                                                    test_size = .20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37b5647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bd10cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['Sex'] = encoder.fit_transform(x_train[['Sex']])\n",
    "x_test['Sex'] = encoder.fit_transform(x_test[['Sex']])\n",
    "x_train['Embarked'] = encoder.fit_transform(x_train[['Embarked']])\n",
    "x_test['Embarked'] = encoder.fit_transform(x_test[['Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d5cf262",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=[len(column_x)]),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b34d137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='SGD',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics =['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "867605b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50/50 [==============================] - 0s 611us/step - loss: nan - accuracy: 0.6408\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 0s 692us/step - loss: nan - accuracy: 0.6580\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 0s 651us/step - loss: nan - accuracy: 0.6466\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 0s 651us/step - loss: nan - accuracy: 0.6379\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 0s 656us/step - loss: nan - accuracy: 0.6580\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.6293\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 0s 651us/step - loss: nan - accuracy: 0.6494\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 0s 611us/step - loss: nan - accuracy: 0.6667\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 0s 631us/step - loss: nan - accuracy: 0.6523\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 0s 631us/step - loss: nan - accuracy: 0.6466\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 0s 631us/step - loss: nan - accuracy: 0.6236\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 0s 611us/step - loss: nan - accuracy: 0.6494\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 0s 611us/step - loss: nan - accuracy: 0.6322\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 0s 611us/step - loss: nan - accuracy: 0.6494\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 0s 631us/step - loss: nan - accuracy: 0.6580\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 0s 635us/step - loss: nan - accuracy: 0.6437\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 0s 631us/step - loss: nan - accuracy: 0.6552\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 0s 652us/step - loss: nan - accuracy: 0.6293\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 0s 692us/step - loss: nan - accuracy: 0.6609\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 0s 693us/step - loss: nan - accuracy: 0.6322\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 0s 692us/step - loss: nan - accuracy: 0.6638\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 0s 733us/step - loss: nan - accuracy: 0.6379\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 0s 712us/step - loss: nan - accuracy: 0.6523\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 0s 672us/step - loss: nan - accuracy: 0.6474\n",
      "Epoch 25/25\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1250 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 0s 200us/step - loss: nan - accuracy: 0.6474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x177664cac80>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=25,\n",
    "    steps_per_epoch=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a90c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
